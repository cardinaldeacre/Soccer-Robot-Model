{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7738614,"sourceType":"datasetVersion","datasetId":4522908}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"try:\n    from ultralytics import YOLO\n    print(\"Ultralytics sudah ada ‚úÖ\")\nexcept:\n    print(\"Install ultralytics dulu ‚è≥\")\n    !pip install ultralytics\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:22:28.506157Z","iopub.execute_input":"2026-01-06T02:22:28.506505Z","iopub.status.idle":"2026-01-06T02:22:33.796836Z","shell.execute_reply.started":"2026-01-06T02:22:28.506473Z","shell.execute_reply":"2026-01-06T02:22:33.796092Z"}},"outputs":[{"name":"stdout","text":"Install ultralytics dulu ‚è≥\nCollecting ultralytics\n  Downloading ultralytics-8.3.248-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\nCollecting ultralytics-thop>=2.0.18 (from ultralytics)\n  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\nDownloading ultralytics-8.3.248-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.3.248 ultralytics-thop-2.0.18\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import json\nimport os\nimport shutil\nfrom PIL import Image\n\nIMAGE_SRC_DIR = \"/kaggle/input/balls-detection/oi5_ball\"\nJSON_PATH = \"/kaggle/input/balls-detection/oi5_ball_filename_to_bbox_train.json\"\nOUT_BASE = \"/kaggle/working/dataset\"\nIMG_OUT = os.path.join(OUT_BASE, \"images/train\")\nLBL_OUT = os.path.join(OUT_BASE, \"labels/train\")\n\nos.makedirs(IMG_OUT, exist_ok=True)\nos.makedirs(LBL_OUT, exist_ok=True)\n\nwith open(JSON_PATH, \"r\") as f:\n    data = json.load(f)\n\nprint(\"total image: \", len(data))\n\n# convert\n\nfor img_rel_path, bboxes in data.items():\n    img_name = os.path.basename(img_rel_path)\n    img_src = os.path.join(IMAGE_SRC_DIR, img_name)\n\n    if not os.path.exists(img_src):\n        continue\n\n    img = Image.open(img_src)\n    w, h = img.size\n\n    label_lines = []\n    \n    for box in bboxes:\n        x_center, y_center, bw_norm, bh_norm = box\n    \n        label_lines.append(\n            f\"0 {x_center:.6f} {y_center:.6f} {bw_norm:.6f} {bh_norm:.6f}\"\n        )\n\n    # save label\n    label_path = os.path.join(LBL_OUT, img_name.replace(\".jpg\", \".txt\"))\n    with open(label_path, \"w\") as f:\n        f.write(\"\\n\".join(label_lines))\n\n    # copy image\n    shutil.copy(img_src, os.path.join(IMG_OUT, img_name))\n\nprint(\"konversi selesai\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:22:33.798449Z","iopub.execute_input":"2026-01-06T02:22:33.798724Z","iopub.status.idle":"2026-01-06T02:23:08.246545Z","shell.execute_reply.started":"2026-01-06T02:22:33.798697Z","shell.execute_reply":"2026-01-06T02:23:08.245898Z"}},"outputs":[{"name":"stdout","text":"total image:  2875\nkonversi selesai\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport random\nimport shutil\n\nBASE = \"/kaggle/working/dataset\"\nIMG_TRAIN = f\"{BASE}/images/train\"\nLBL_TRAIN = f\"{BASE}/labels/train\"\n\nIMG_VAL = f\"{BASE}/images/val\"\nLBL_VAL = f\"{BASE}/labels/val\"\n\nos.makedirs(IMG_VAL, exist_ok=True)\nos.makedirs(LBL_VAL, exist_ok=True)\nos.makedirs(\"/kaggle/working/images/val\", exist_ok=True)\nos.makedirs(\"/kaggle/working/labels/val\", exist_ok=True)\nos.makedirs(\"/kaggle/working/images/train\", exist_ok=True)\nos.makedirs(\"/kaggle/working/labels/train\", exist_ok=True)\n\nimgs = os.listdir(IMG_TRAIN)\nrandom.shuffle(imgs)\n\nval_count = int(0.1 * len(imgs))\nval_imgs = imgs[:val_count]\n\nfor img in val_imgs:\n    shutil.move(f\"{IMG_TRAIN}/{img}\", f\"{IMG_VAL}/{img}\")\n    shutil.move(\n        f\"{LBL_TRAIN}/{img.replace('.jpg','.txt')}\",\n        f\"{LBL_VAL}/{img.replace('.jpg','.txt')}\"\n    )\n\nprint(f\"Val images: {len(val_imgs)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:23:08.247323Z","iopub.execute_input":"2026-01-06T02:23:08.247605Z","iopub.status.idle":"2026-01-06T02:23:08.273719Z","shell.execute_reply.started":"2026-01-06T02:23:08.247582Z","shell.execute_reply":"2026-01-06T02:23:08.272367Z"}},"outputs":[{"name":"stdout","text":"Val images: 287\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os, shutil, random\nfrom glob import glob\n\nSRC_IMG = \"/kaggle/input/balls-detection/oi5_ball\"\nSRC_LBL = \"/kaggle/working/dataset/labels/train\"\n\nDST_IMG_TRAIN = \"/kaggle/working/images/train\"\nDST_IMG_VAL   = \"/kaggle/working/images/val\"\nDST_LBL_TRAIN = \"/kaggle/working/labels/train\"\nDST_LBL_VAL   = \"/kaggle/working/labels/val\"\n\nos.makedirs(DST_IMG_TRAIN, exist_ok=True)\nos.makedirs(DST_IMG_VAL, exist_ok=True)\nos.makedirs(DST_LBL_TRAIN, exist_ok=True)\nos.makedirs(DST_LBL_VAL, exist_ok=True)\n\nlabels = glob(f\"{SRC_LBL}/*.txt\")\nrandom.shuffle(labels)\n\nval_ratio = 0.1\nval_count = int(len(labels) * val_ratio)\n\nfor i, lbl in enumerate(labels):\n    name = os.path.basename(lbl).replace(\".txt\", \".jpg\")\n    img_path = f\"{SRC_IMG}/{name}\"\n\n    if not os.path.exists(img_path):\n        continue\n\n    if i < val_count:\n        shutil.copy(img_path, f\"{DST_IMG_VAL}/{name}\")\n        shutil.copy(lbl, f\"{DST_LBL_VAL}/{name.replace('.jpg','.txt')}\")\n    else:\n        shutil.copy(img_path, f\"{DST_IMG_TRAIN}/{name}\")\n        shutil.copy(lbl, f\"{DST_LBL_TRAIN}/{name.replace('.jpg','.txt')}\")\n\nprint(\"dataset filtered & rebuilt CLEAN üßºüî•\")\n\n!ls /kaggle/working/images/train | wc -l\n!ls /kaggle/working/images/val | wc -l\n!ls /kaggle/working/labels/train | wc -l\n!ls /kaggle/working/labels/val | wc -l","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:23:08.275501Z","iopub.execute_input":"2026-01-06T02:23:08.275766Z","iopub.status.idle":"2026-01-06T02:23:12.625561Z","shell.execute_reply.started":"2026-01-06T02:23:08.275745Z","shell.execute_reply":"2026-01-06T02:23:12.624640Z"}},"outputs":[{"name":"stdout","text":"dataset filtered & rebuilt CLEAN üßºüî•\n2330\n258\n2330\n258\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import shutil\nimport random\nfrom glob import glob\n\ntrain_imgs = glob(\"/kaggle/working/images/train/*.jpg\")\nrandom.shuffle(train_imgs)\n\nval_count = int(0.1 * len(train_imgs))\nval_imgs = train_imgs[:val_count]\n\nfor img_path in val_imgs:\n    name = os.path.basename(img_path)\n\n    # pindah img\n    shutil.move(\n        img_path,\n        f\"/kaggle/working/images/val/{name}\"\n    )\n\n    # pundah label\n    shutil.move(\n        f\"/kaggle/working/labels/train/{name.replace('.jpg','.txt')}\",\n        f\"/kaggle/working/labels/val/{name.replace('.jpg','.txt')}\"\n    )\n\nprint(\"train-val split DONE\")\n!ls /kaggle/working/images/train | wc -l\n!ls /kaggle/working/images/val | wc -l\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:23:12.626790Z","iopub.execute_input":"2026-01-06T02:23:12.627080Z","iopub.status.idle":"2026-01-06T02:23:12.880081Z","shell.execute_reply.started":"2026-01-06T02:23:12.627049Z","shell.execute_reply":"2026-01-06T02:23:12.879400Z"}},"outputs":[{"name":"stdout","text":"train-val split DONE\n2097\n491\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from ultralytics import YOLO\n\n# tulis file di terrminal\n# %%writefile data.yaml\n# path: /kaggle/working\n# train: images/train\n# val: images/val\n\n# nc: 1\n# names:\n#   - ball\n\nmodel = YOLO(\"yolov8n.pt\")\n\nmodel.train(\n    data=\"/kaggle/working/data.yaml\",\n    epochs=50,\n    imgsz=416,\n    batch=16,\n    device=0\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:23:12.881240Z","iopub.execute_input":"2026-01-06T02:23:12.881825Z","iopub.status.idle":"2026-01-06T02:38:03.477096Z","shell.execute_reply.started":"2026-01-06T02:23:12.881793Z","shell.execute_reply":"2026-01-06T02:38:03.476420Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 103.9MB/s 0.1s\nUltralytics 8.3.248 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=416, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 24.7MB/s 0.0s\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.4MB 89.2MB/s 0.1s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3455.5¬±797.7 MB/s, size: 274.9 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/labels/train... 2097 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2097/2097 1.5Kit/s 1.4s0.1s\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1721.5¬±1065.0 MB/s, size: 248.0 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/labels/val... 491 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 491/491 1.7Kit/s 0.3s<0.1s\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/labels/val.cache\nPlotting labels to /kaggle/working/runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 416 train, 416 val\nUsing 4 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/train\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/50      1.02G       2.39      2.853      2.414          2        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 6.1it/s 21.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 4.9it/s 3.2s0.2s\n                   all        491        918      0.109     0.0795     0.0325    0.00901\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/50      1.41G      2.226      2.822      2.363          4        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.7it/s 15.1s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.1s0.1s\n                   all        491        918     0.0202      0.155    0.00999    0.00253\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/50      1.43G      2.179      2.873       2.37          3        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.9it/s 14.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.0s0.1s\n                   all        491        918     0.0298     0.0632     0.0189    0.00596\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/50      1.45G      2.105      2.849       2.38          4        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.9it/s 14.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.7it/s 2.1s0.1s\n                   all        491        918     0.0565     0.0414     0.0189    0.00545\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/50      1.46G      2.076      2.833      2.363          8        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.4it/s 2.2s0.1s\n                   all        491        918     0.0389     0.0556     0.0115    0.00284\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/50      1.48G       2.03      2.822      2.316          2        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.9it/s 14.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.9it/s 2.0s0.1s\n                   all        491        918      0.132     0.0595     0.0402     0.0116\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/50       1.5G       1.97      2.764      2.284          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.1s0.1s\n                   all        491        918      0.109      0.146     0.0565     0.0162\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/50      1.52G      1.966      2.762      2.258          6        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.9it/s 14.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.5it/s 2.1s0.1s\n                   all        491        918      0.203      0.117     0.0826     0.0266\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/50      1.53G      1.964      2.756      2.287          3        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.9it/s 14.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.7it/s 2.1s0.1s\n                   all        491        918      0.147      0.144     0.0684     0.0223\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/50      1.55G      1.932      2.713      2.233          2        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.9it/s 2.0s0.1s\n                   all        491        918      0.274      0.112     0.0957     0.0293\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      11/50      1.57G        1.9      2.691      2.207          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.9it/s 2.0s0.1s\n                   all        491        918      0.214      0.148     0.0965     0.0293\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      12/50      1.58G      1.907      2.669      2.206          5        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.6it/s 2.1s0.1s\n                   all        491        918       0.21      0.154     0.0926     0.0309\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      13/50       1.6G      1.896      2.723      2.204          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.0s0.1s\n                   all        491        918      0.171      0.133     0.0856     0.0289\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      14/50      1.62G      1.861      2.653      2.178          4        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.6s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.7it/s 2.1s0.1s\n                   all        491        918      0.225      0.157      0.119     0.0372\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      15/50      1.63G      1.872      2.643      2.176         15        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.0s0.1s\n                   all        491        918      0.256      0.181       0.12     0.0426\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      16/50      1.65G      1.841      2.616      2.146          4        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.1it/s 2.0s0.1s\n                   all        491        918      0.208      0.168       0.11     0.0411\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      17/50      1.67G      1.836      2.616      2.138          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.0it/s 2.0s0.1s\n                   all        491        918      0.202      0.155       0.09     0.0311\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      18/50      1.69G      1.852      2.597      2.153          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.9it/s 14.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.9it/s 2.0s0.1s\n                   all        491        918      0.246      0.192       0.13     0.0476\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      19/50       1.7G      1.807      2.566      2.125          3        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.0s0.1s\n                   all        491        918      0.255      0.227      0.158     0.0621\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      20/50      1.72G      1.787      2.545      2.111          6        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.0s0.1s\n                   all        491        918      0.272      0.211      0.152     0.0568\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      21/50      1.74G      1.777      2.537      2.094          3        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.6s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.1s0.1s\n                   all        491        918      0.238      0.197      0.125     0.0432\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      22/50      1.75G      1.779      2.522      2.094          5        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.9it/s 14.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.0it/s 2.0s0.1s\n                   all        491        918      0.332      0.218      0.188     0.0716\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      23/50      1.77G      1.767      2.489      2.087          2        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.1it/s 2.0s0.1s\n                   all        491        918      0.301      0.259      0.184     0.0728\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      24/50      1.79G      1.745      2.475      2.072          2        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.1s0.1s\n                   all        491        918      0.302      0.233      0.186     0.0744\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      25/50       1.8G      1.743      2.485      2.057          4        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.9it/s 2.0s0.1s\n                   all        491        918      0.262      0.239      0.156     0.0662\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      26/50      1.82G      1.755      2.469      2.062         10        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.6s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.7it/s 2.1s0.1s\n                   all        491        918      0.307      0.271      0.205     0.0804\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      27/50      1.84G       1.72      2.464      2.046          2        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.9it/s 2.0s0.1s\n                   all        491        918      0.267      0.277      0.181     0.0705\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      28/50      1.99G      1.713      2.423      2.046          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.9it/s 14.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.1it/s 2.0s0.1s\n                   all        491        918      0.289      0.284      0.195     0.0773\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      29/50      2.01G      1.709      2.412      2.046          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.1it/s 14.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.0s0.1s\n                   all        491        918      0.325      0.281      0.199     0.0821\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      30/50      2.03G        1.7      2.448      2.009          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.6s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.0it/s 2.0s0.1s\n                   all        491        918      0.304      0.298      0.196     0.0795\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      31/50      2.04G      1.704      2.414      2.032          4        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.0it/s 2.0s0.1s\n                   all        491        918      0.301      0.308       0.19     0.0784\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      32/50      2.06G      1.722      2.413      2.043          5        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.0it/s 2.0s0.1s\n                   all        491        918      0.284      0.259      0.184     0.0735\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      33/50      2.08G      1.709      2.412       2.03          2        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.9it/s 14.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.0it/s 2.0s0.1s\n                   all        491        918      0.311      0.309       0.21     0.0878\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      34/50       2.1G      1.676      2.372      2.023          3        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.1it/s 2.0s0.1s\n                   all        491        918      0.281      0.325      0.199     0.0829\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      35/50      2.11G      1.677      2.361      1.996          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.9it/s 14.8s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.0it/s 2.0s0.1s\n                   all        491        918      0.309      0.308      0.212     0.0905\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      36/50      2.13G      1.655      2.361      1.992          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.0it/s 2.0s0.1s\n                   all        491        918      0.317      0.295      0.217     0.0957\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      37/50      2.15G      1.646       2.31       1.99         15        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.1it/s 2.0s0.1s\n                   all        491        918       0.35       0.32      0.221      0.102\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      38/50      2.16G      1.629      2.331      1.969          2        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.1it/s 2.0s0.1s\n                   all        491        918      0.313      0.317      0.213     0.0945\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      39/50      2.18G      1.622      2.318      1.979          2        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.9it/s 2.0s0.1s\n                   all        491        918      0.331      0.328      0.229      0.105\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      40/50       2.2G      1.632      2.327      1.971          2        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.0it/s 14.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.2it/s 1.9s0.1s\n                   all        491        918      0.322      0.333      0.225      0.107\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      41/50      2.21G       1.57      2.369      1.919          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 8.3it/s 16.0s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.0s0.1s\n                   all        491        918      0.358      0.345      0.259      0.118\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      42/50      2.23G      1.469       2.15      1.844          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.1it/s 14.4s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.9it/s 2.0s0.1s\n                   all        491        918      0.376      0.368      0.272      0.126\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      43/50      2.25G      1.455      2.087      1.834         11        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.2it/s 14.4s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.9it/s 2.0s0.1s\n                   all        491        918      0.357      0.357      0.262      0.124\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      44/50      2.27G      1.439      2.034      1.825          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.1it/s 14.4s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.1it/s 2.0s0.1s\n                   all        491        918      0.388      0.356       0.27       0.13\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      45/50      2.28G      1.429      2.042      1.812          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.1it/s 14.5s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.2it/s 2.0s0.1s\n                   all        491        918      0.368      0.344       0.26       0.13\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      46/50       2.3G      1.414      1.992      1.797          3        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.1it/s 14.5s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.9it/s 2.0s0.1s\n                   all        491        918      0.406      0.366       0.29      0.138\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      47/50      2.32G        1.4      1.976      1.782          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.1it/s 14.4s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.1it/s 2.0s0.1s\n                   all        491        918      0.409      0.368      0.306      0.157\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      48/50      2.33G      1.401      1.957      1.793          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.2it/s 14.4s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.1it/s 2.0s0.1s\n                   all        491        918       0.41      0.376      0.296       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      49/50      2.35G      1.378      1.941      1.773          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.1it/s 14.4s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 8.2it/s 2.0s0.1s\n                   all        491        918      0.417      0.371      0.299      0.154\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      50/50      2.37G      1.366      1.918       1.76          1        416: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 9.2it/s 14.4s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 7.8it/s 2.1s0.1s\n                   all        491        918      0.405       0.38      0.304      0.156\n\n50 epochs completed in 0.239 hours.\nOptimizer stripped from /kaggle/working/runs/detect/train/weights/last.pt, 6.2MB\nOptimizer stripped from /kaggle/working/runs/detect/train/weights/best.pt, 6.2MB\n\nValidating /kaggle/working/runs/detect/train/weights/best.pt...\nUltralytics 8.3.248 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.4s0.1s\n                   all        491        918      0.409      0.367      0.306      0.157\nSpeed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 1.1ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/train\u001b[0m\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"ultralytics.utils.metrics.DetMetrics object with attributes:\n\nap_class_index: array([0])\nbox: ultralytics.utils.metrics.Metric object\nconfusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7d832415b590>\ncurves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\ncurves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.94118,     0.93103,     0.93103,     0.93103,     0.93103,     0.93103,\n            0.93103,     0.93103,     0.93103,     0.93103,     0.93103,     0.93103,     0.93103,     0.90625,     0.90625,     0.89189,     0.89189,     0.89189,     0.89189,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88889,     0.88462,     0.88462,\n            0.88462,     0.88462,     0.88462,     0.88462,     0.88462,     0.84211,     0.84211,     0.83784,     0.83784,     0.83784,     0.83784,     0.83784,     0.83784,     0.83784,     0.83784,     0.83784,     0.83784,     0.83784,     0.83784,     0.83784,     0.83784,     0.83784,     0.83117,\n            0.83117,       0.825,       0.825,     0.81319,     0.81319,     0.81319,     0.81319,     0.81319,     0.81319,     0.81319,     0.81319,     0.81319,     0.80645,     0.77143,     0.77143,     0.77143,     0.77143,     0.77143,     0.77143,     0.77143,     0.76106,     0.76106,     0.76106,\n            0.76106,     0.76106,        0.75,        0.75,        0.75,        0.75,      0.7459,      0.7459,     0.74436,     0.74436,     0.74436,     0.74436,     0.74436,     0.74436,     0.74436,     0.74436,     0.74265,     0.74265,     0.73381,      0.7305,      0.7305,     0.71233,      0.7047,\n            0.70199,     0.69935,     0.69677,     0.68987,     0.67901,     0.67879,     0.67879,     0.67262,     0.66279,     0.66279,     0.66092,     0.64865,     0.64865,     0.64865,     0.64865,     0.64865,     0.64211,     0.64211,     0.64141,     0.64141,     0.64141,     0.64141,     0.64141,\n            0.64141,     0.63682,     0.63592,     0.63592,     0.63592,     0.63158,     0.62326,     0.62326,     0.62232,     0.62232,     0.62232,     0.62232,     0.62232,     0.62232,     0.62232,     0.62232,     0.62232,     0.62232,     0.62232,     0.62232,     0.61832,     0.61832,     0.61832,\n            0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61832,     0.61509,     0.60886,     0.60886,     0.60584,     0.60211,     0.60211,     0.60211,\n            0.60211,     0.60211,     0.60211,         0.6,         0.6,         0.6,     0.59932,     0.59871,     0.59871,     0.59871,     0.59871,     0.59871,     0.59871,     0.59871,     0.59871,     0.59871,     0.59871,     0.59871,     0.59365,     0.59365,     0.58696,     0.58696,     0.58055,\n            0.58055,     0.57647,     0.57647,     0.57647,     0.57647,     0.57647,     0.57647,     0.57602,     0.57558,     0.57184,     0.56941,     0.56941,     0.56742,     0.56474,     0.56474,     0.56474,     0.56474,     0.56131,     0.56122,     0.56122,     0.56122,     0.56122,     0.56122,\n            0.56122,     0.56122,     0.56122,     0.56122,     0.56122,     0.56122,     0.56122,     0.56122,     0.56122,     0.56122,     0.56091,     0.56061,     0.55611,     0.55583,     0.55556,     0.55528,     0.55048,     0.55048,     0.55048,     0.55048,     0.54762,      0.5461,     0.54312,\n            0.54312,     0.54292,     0.54157,     0.54157,     0.54157,     0.54157,     0.54157,     0.54157,     0.54157,     0.54157,        0.54,        0.54,     0.53982,     0.53846,     0.53132,     0.51633,     0.51633,     0.51633,     0.51633,     0.51633,     0.51633,     0.51633,     0.51633,\n            0.51613,     0.51613,     0.51613,     0.51606,       0.516,     0.50973,     0.50973,     0.50973,     0.50973,     0.50973,     0.50287,     0.50285,     0.50285,     0.49627,     0.49543,     0.49543,     0.49543,     0.49543,     0.49543,     0.49186,     0.49117,     0.49117,     0.49117,\n            0.49117,     0.49117,     0.49117,     0.49117,     0.48951,     0.48951,      0.4887,     0.48211,     0.48211,     0.47892,     0.47892,     0.47595,     0.47595,     0.47595,     0.47455,     0.47455,     0.47154,     0.47087,     0.46434,     0.46434,     0.46154,     0.45525,     0.45525,\n            0.45469,     0.45413,     0.45263,     0.45263,     0.45263,     0.45263,      0.4521,     0.45089,     0.43948,     0.43948,      0.4392,      0.4392,      0.4392,     0.43875,      0.4383,     0.43759,     0.43759,     0.43759,      0.4375,      0.4375,      0.4375,      0.4375,      0.4375,\n             0.4375,      0.4375,      0.4375,      0.4375,      0.4375,      0.4375,     0.43649,     0.43548,     0.43449,     0.42634,     0.42634,     0.41858,     0.41858,     0.41858,     0.41509,     0.41315,     0.41315,     0.41315,     0.41082,     0.41054,     0.40948,     0.40948,     0.40071,\n            0.40071,         0.4,      0.3993,      0.3993,     0.39884,     0.39884,     0.39884,     0.39884,     0.39839,     0.39839,     0.39771,     0.39569,     0.38889,      0.3887,     0.38816,     0.38816,     0.38816,     0.38816,     0.38585,     0.38585,     0.38585,     0.38585,     0.38585,\n            0.38585,     0.38552,     0.38552,     0.37863,     0.37863,     0.37863,     0.37863,     0.37233,     0.37033,     0.36763,     0.36643,     0.36597,     0.36089,     0.35873,     0.35797,     0.35383,     0.35211,     0.35211,     0.34912,     0.34862,     0.34862,     0.34862,     0.34862,\n            0.34636,     0.34508,     0.34367,     0.34367,     0.34367,     0.34367,     0.34367,     0.34367,     0.34367,     0.34273,     0.34121,     0.34119,     0.34028,     0.33647,     0.32643,     0.32537,     0.32091,     0.31965,     0.31965,     0.31965,     0.31965,     0.31965,     0.31965,\n            0.31965,     0.31965,     0.31965,     0.31965,     0.31918,     0.31825,     0.31825,     0.31705,     0.31705,     0.31563,     0.31326,       0.307,     0.30486,     0.30486,     0.30358,     0.30152,     0.30152,     0.29857,      0.2957,     0.29432,     0.29432,     0.29404,     0.29404,\n            0.29404,     0.29404,     0.28951,     0.28726,     0.28638,     0.28638,     0.28638,     0.28638,     0.28638,     0.28638,      0.2859,     0.28553,     0.28553,      0.2801,     0.27859,     0.27641,      0.2753,     0.27301,     0.27228,     0.27072,     0.26448,     0.26448,     0.26448,\n            0.26441,     0.26441,     0.26266,     0.26186,     0.26184,      0.2576,     0.25295,     0.25266,     0.25195,     0.25181,     0.25152,     0.25152,     0.25152,     0.24918,     0.24878,     0.24878,     0.24402,     0.23864,     0.23864,     0.23864,     0.23854,     0.23506,     0.23273,\n            0.23273,     0.23184,     0.22881,     0.22674,     0.22668,     0.22222,      0.2138,       0.213,     0.21013,     0.20844,     0.20607,     0.20588,     0.20569,     0.20569,     0.20375,     0.20118,     0.19688,     0.19609,     0.19609,     0.19452,     0.19352,     0.18856,     0.18856,\n            0.18856,     0.18856,     0.18856,     0.18721,     0.18695,     0.18556,     0.18496,     0.18229,     0.18229,     0.18199,     0.17932,     0.17897,     0.17764,     0.17764,     0.17764,     0.17728,     0.17728,     0.17497,     0.17459,     0.17452,     0.17378,     0.17252,     0.17245,\n            0.17018,     0.16882,     0.16832,     0.16776,     0.16776,      0.1677,     0.16591,     0.16591,     0.16406,     0.16288,     0.16136,     0.15998,     0.15857,     0.15777,     0.15671,     0.15671,     0.15671,     0.15199,     0.15075,     0.14884,     0.14884,     0.14754,     0.14634,\n            0.14469,     0.14103,     0.13916,     0.13916,     0.13773,     0.13773,      0.1365,     0.13573,     0.13573,     0.13465,     0.13033,     0.13016,     0.12357,     0.12287,     0.12287,     0.12127,     0.12127,     0.11983,     0.11983,     0.11968,     0.11876,     0.11826,      0.1169,\n             0.1169,     0.11368,     0.11305,     0.11267,     0.11124,      0.1096,     0.10629,     0.10629,     0.10326,     0.10326,     0.10108,    0.098853,    0.097447,    0.097299,    0.096586,    0.095955,    0.095955,    0.095955,    0.095955,    0.095955,    0.095849,    0.095502,    0.091537,\n           0.091112,    0.088081,     0.08787,    0.087221,    0.085808,    0.085207,    0.083903,    0.080726,     0.08045,     0.08045,    0.080315,    0.080315,    0.080038,    0.080038,    0.079798,    0.079798,    0.076984,    0.075859,    0.075259,    0.074548,    0.074074,    0.074074,    0.073107,\n           0.072656,    0.071853,    0.071739,    0.069737,    0.069626,    0.069081,    0.069061,    0.068914,    0.067461,    0.066622,    0.066622,     0.06638,    0.066278,    0.065016,    0.064123,    0.062147,    0.060621,    0.060144,    0.059566,    0.059233,    0.059233,    0.059233,    0.059141,\n           0.059141,    0.058784,     0.05841,    0.056774,    0.056296,    0.054894,    0.054329,    0.054329,    0.053965,    0.053965,    0.053679,    0.051265,    0.051265,    0.048584,    0.048584,    0.048578,    0.048071,    0.048048,    0.047666,    0.047504,    0.046158,    0.046003,    0.045826,\n            0.04567,     0.04567,    0.045614,    0.043189,    0.042733,    0.042228,    0.041989,    0.040779,    0.040067,    0.039431,    0.038697,     0.03856,    0.038126,     0.03754,     0.03754,    0.035742,    0.035245,     0.03447,     0.03447,    0.034195,    0.033043,     0.03251,    0.032282,\n            0.03108,    0.031054,    0.030222,    0.030222,    0.029923,    0.029561,    0.029281,    0.028374,     0.02663,    0.026586,    0.026412,    0.026392,    0.025157,    0.023892,    0.023892,    0.023892,    0.023611,    0.022846,    0.022458,    0.022357,    0.022291,    0.021964,    0.021371,\n           0.021252,    0.020878,    0.018017,    0.017909,    0.017634,    0.017634,    0.016635,    0.016186,    0.015991,    0.015991,    0.015907,    0.015865,    0.015561,    0.015518,    0.014783,    0.014363,    0.014199,    0.014199,    0.014199,    0.014199,    0.013734,    0.013641,    0.013605,\n            0.01252,    0.012316,    0.011763,     0.01166,    0.011611,    0.011562,    0.011513,    0.011464,    0.011414,    0.011365,    0.011316,    0.011267,    0.011218,    0.011168,    0.011119,     0.01107,    0.011021,    0.010972,    0.010922,    0.010873,    0.010824,    0.010775,    0.010726,\n           0.010676,    0.010627,    0.010578,    0.010529,     0.01048,     0.01043,    0.010381,    0.010332,    0.010283,    0.010234,    0.010184,    0.010135,    0.010086,    0.010037,   0.0099876,   0.0099384,   0.0098892,     0.00984,   0.0097908,   0.0097416,   0.0096924,   0.0096432,    0.009594,\n          0.0095448,   0.0094956,   0.0094464,   0.0093972,    0.009348,   0.0092988,   0.0092496,   0.0092004,   0.0091512,    0.009102,   0.0090528,   0.0090036,   0.0089544,   0.0089052,    0.008856,   0.0088068,   0.0087576,   0.0087084,   0.0086592,     0.00861,   0.0085608,   0.0085116,   0.0084624,\n          0.0084132,    0.008364,   0.0083148,   0.0082656,   0.0082164,   0.0081672,    0.008118,   0.0080688,   0.0080196,   0.0079704,   0.0079212,    0.007872,   0.0078228,   0.0077736,   0.0077244,   0.0076752,    0.007626,   0.0075768,   0.0075276,   0.0074784,   0.0074292,     0.00738,   0.0073308,\n          0.0072816,   0.0072324,   0.0071832,    0.007134,   0.0070848,   0.0070356,   0.0069864,   0.0069372,    0.006888,   0.0068388,   0.0067896,   0.0067404,   0.0066912,    0.006642,   0.0065928,   0.0065436,   0.0064944,   0.0064452,    0.006396,   0.0063468,   0.0062976,   0.0062484,   0.0061992,\n            0.00615,   0.0061008,   0.0060516,   0.0060024,   0.0059532,    0.005904,   0.0058548,   0.0058056,   0.0057564,   0.0057072,    0.005658,   0.0056088,   0.0055596,   0.0055104,   0.0054612,    0.005412,   0.0053628,   0.0053136,   0.0052644,   0.0052152,    0.005166,   0.0051168,   0.0050676,\n          0.0050184,   0.0049692,     0.00492,   0.0048708,   0.0048216,   0.0047724,   0.0047232,    0.004674,   0.0046248,   0.0045756,   0.0045264,   0.0044772,    0.004428,   0.0043788,   0.0043296,   0.0042804,   0.0042312,    0.004182,   0.0041328,   0.0040836,   0.0040344,   0.0039852,    0.003936,\n          0.0038868,   0.0038376,   0.0037884,   0.0037392,     0.00369,   0.0036408,   0.0035916,   0.0035424,   0.0034932,    0.003444,   0.0033948,   0.0033456,   0.0032964,   0.0032472,    0.003198,   0.0031488,   0.0030996,   0.0030504,   0.0030012,    0.002952,   0.0029028,   0.0028536,   0.0028044,\n          0.0027552,    0.002706,   0.0026568,   0.0026076,   0.0025584,   0.0025092,     0.00246,   0.0024108,   0.0023616,   0.0023124,   0.0022632,    0.002214,   0.0021648,   0.0021156,   0.0020664,   0.0020172,    0.001968,   0.0019188,   0.0018696,   0.0018204,   0.0017712,    0.001722,   0.0016728,\n          0.0016236,   0.0015744,   0.0015252,    0.001476,   0.0014268,   0.0013776,   0.0013284,   0.0012792,     0.00123,   0.0011808,   0.0011316,   0.0010824,   0.0010332,    0.000984,   0.0009348,   0.0008856,   0.0008364,   0.0007872,    0.000738,   0.0006888,   0.0006396,   0.0005904,   0.0005412,\n           0.000492,   0.0004428,   0.0003936,   0.0003444,   0.0002952,    0.000246,   0.0001968,   0.0001476,    9.84e-05,    4.92e-05,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.022992,    0.022992,    0.039264,    0.053271,    0.065751,    0.076975,    0.087518,    0.097017,     0.10576,     0.11307,     0.12125,      0.1282,     0.13471,     0.14162,     0.14725,     0.15341,     0.15928,     0.16525,     0.16895,     0.17378,     0.17924,     0.18489,     0.18899,\n            0.19339,     0.19735,     0.20054,     0.20418,       0.208,      0.2118,     0.21548,     0.21993,     0.22307,     0.22663,     0.23011,     0.23345,     0.23649,     0.23969,     0.24306,     0.24657,     0.24902,     0.25234,     0.25511,     0.25686,     0.25839,     0.26016,     0.26332,\n            0.26479,     0.26746,     0.26921,     0.27124,      0.2725,     0.27483,     0.27662,     0.27799,     0.27893,     0.28201,     0.28405,     0.28588,     0.28763,     0.28983,     0.29073,     0.29287,     0.29432,      0.2948,      0.2966,     0.29859,     0.30118,     0.30176,      0.3053,\n            0.30843,     0.30988,     0.31205,     0.31377,      0.3152,     0.31677,     0.31831,     0.31975,     0.32118,     0.32367,     0.32281,     0.32445,     0.32578,     0.32796,     0.32886,     0.33049,     0.33095,     0.33205,     0.33357,     0.33301,     0.33356,     0.33595,     0.33699,\n            0.33802,     0.33961,     0.34047,     0.34092,     0.34187,     0.34084,     0.34307,     0.34452,      0.3457,     0.34688,     0.34738,      0.3474,     0.34899,     0.35011,     0.35135,     0.35201,     0.35281,     0.35499,     0.35535,     0.35508,      0.3541,     0.35387,     0.35456,\n              0.356,     0.35718,     0.35852,     0.35735,     0.35753,     0.35805,     0.35874,     0.35956,     0.36031,     0.36128,      0.3615,      0.3627,     0.36319,     0.36401,     0.36397,     0.36542,     0.36644,     0.36791,      0.3695,     0.37017,     0.37042,     0.37046,     0.36988,\n             0.3682,     0.36576,     0.36616,     0.36779,     0.36791,     0.36982,     0.36983,     0.37048,      0.3706,      0.3722,     0.37307,     0.37432,      0.3763,      0.3763,     0.37788,     0.37822,     0.37808,     0.37823,     0.37709,     0.37728,     0.37558,     0.37728,     0.37751,\n            0.37748,     0.37822,     0.37701,     0.37668,     0.37692,     0.37812,     0.37814,     0.37824,     0.37956,     0.37981,     0.38095,     0.38069,     0.38198,     0.38314,     0.38262,     0.38336,     0.38287,     0.38432,     0.38449,     0.38588,     0.38698,     0.38684,     0.38707,\n             0.3882,     0.38936,     0.38898,     0.38662,     0.38606,     0.38574,     0.38611,     0.38685,     0.38441,     0.38531,     0.38424,     0.38508,     0.38608,     0.38654,     0.38759,     0.38726,     0.38791,     0.38601,     0.38535,     0.38549,     0.38458,     0.38449,      0.3835,\n            0.38306,     0.38431,     0.38565,     0.38699,     0.38542,     0.38573,     0.38536,       0.386,     0.38462,     0.38445,     0.38504,     0.38514,     0.38606,     0.38463,     0.38621,     0.38705,     0.38739,     0.38682,     0.38798,      0.3888,     0.38938,     0.38995,     0.38941,\n            0.38916,     0.38881,     0.38635,     0.38357,     0.38232,      0.3822,     0.38096,      0.3801,     0.37827,     0.37759,     0.37785,     0.37932,     0.38106,     0.37993,     0.37895,     0.37675,     0.37775,     0.37637,     0.37616,     0.37712,     0.37741,      0.3778,     0.37807,\n            0.37809,     0.37626,     0.37762,      0.3783,     0.37887,     0.37833,     0.37814,     0.37762,     0.37628,     0.37494,     0.37527,     0.37504,     0.37571,     0.37549,      0.3741,      0.3762,     0.37582,     0.37433,      0.3729,     0.36924,     0.36955,     0.36969,     0.36977,\n            0.36795,     0.36636,     0.36483,     0.36556,     0.36573,     0.36622,     0.36556,     0.36469,     0.36494,      0.3651,     0.36557,     0.36543,     0.36265,     0.36209,     0.36313,     0.36346,     0.36248,     0.36201,     0.35892,     0.35597,     0.35549,     0.35296,      0.3533,\n            0.35277,      0.3532,     0.35414,     0.35519,     0.35613,     0.35568,     0.35624,     0.35653,     0.35686,     0.35501,     0.35369,     0.35362,     0.35094,     0.34986,     0.34665,     0.34756,     0.34655,     0.34578,     0.34372,     0.34424,     0.34383,     0.34337,     0.34295,\n            0.34256,      0.3398,      0.3399,     0.34011,     0.33811,     0.33728,     0.33782,     0.33688,     0.33332,     0.33133,     0.32863,     0.32411,     0.32093,     0.31953,     0.32058,     0.31646,     0.31611,     0.31368,     0.31342,     0.31372,     0.31258,     0.31004,      0.3081,\n            0.30564,     0.30522,     0.30424,     0.30427,     0.30295,     0.30015,     0.29461,      0.2937,     0.29346,      0.2927,     0.29088,     0.29035,     0.28918,     0.28868,     0.28785,     0.28421,     0.28447,     0.27935,     0.27775,     0.27807,     0.27823,     0.27715,     0.27622,\n            0.27532,     0.27434,      0.2742,     0.27228,      0.2678,     0.26545,     0.26416,     0.26275,     0.25974,     0.25508,     0.25361,     0.25299,      0.2526,     0.25158,     0.25187,     0.24993,     0.24782,     0.24631,     0.24485,     0.24294,     0.24155,     0.24165,     0.24199,\n            0.24045,     0.23913,     0.23614,     0.23475,      0.2335,     0.23361,     0.23298,     0.23237,     0.23109,     0.23016,     0.23011,     0.22874,     0.22745,     0.22737,      0.2246,      0.2246,     0.22273,     0.21986,     0.21823,     0.21705,     0.21745,     0.21385,     0.20969,\n            0.20976,     0.20983,     0.20998,     0.21018,     0.21037,     0.20767,     0.20685,     0.20553,     0.20441,     0.20206,     0.20095,     0.20114,     0.19966,     0.19666,     0.19534,     0.19509,     0.19384,     0.19418,     0.19428,     0.19395,     0.19135,     0.19156,     0.19052,\n            0.18934,     0.18846,     0.18539,     0.18362,      0.1798,     0.17989,     0.17656,     0.17498,     0.17339,     0.17261,     0.17171,      0.1665,     0.16268,     0.16207,     0.15969,     0.15825,     0.15459,     0.15267,     0.15043,     0.14751,     0.14756,     0.14761,     0.14771,\n            0.14786,     0.14801,     0.14816,     0.14831,     0.14658,     0.14665,     0.14607,     0.14513,     0.14169,     0.13608,      0.1357,     0.13426,     0.13311,     0.13215,     0.13206,     0.13212,     0.13056,     0.12863,     0.12858,     0.12864,     0.12769,     0.12488,     0.11927,\n            0.11862,     0.11797,     0.11524,     0.11157,     0.11092,     0.11026,     0.10953,     0.10854,     0.10728,     0.10594,     0.10569,      0.1047,     0.10371,     0.10271,     0.10216,      0.1022,     0.10223,     0.09931,    0.098368,    0.098381,    0.098394,    0.098407,     0.09842,\n           0.098432,    0.098445,    0.098458,    0.097742,    0.096741,    0.095739,    0.094736,    0.094594,    0.094644,    0.094737,    0.094778,    0.094811,    0.094844,    0.092903,     0.08991,    0.088897,    0.087884,     0.08299,     0.08302,    0.083049,    0.082993,    0.082482,    0.081972,\n           0.081461,    0.080994,    0.080653,    0.080312,    0.079971,    0.079629,    0.079288,    0.078258,    0.076958,    0.076664,    0.076371,    0.076077,    0.075784,     0.07549,    0.075196,    0.074462,    0.073432,    0.072401,    0.071369,    0.069616,    0.069091,    0.066776,    0.066361,\n           0.065945,    0.065529,    0.065113,    0.064542,    0.063947,    0.063351,    0.062081,     0.06102,    0.060003,    0.058642,    0.057943,    0.057243,    0.056999,    0.056694,    0.056168,    0.055642,    0.055115,    0.053447,    0.052595,    0.052172,     0.05175,    0.051327,    0.050903,\n           0.050603,     0.05032,    0.050038,    0.049755,    0.049473,     0.04919,    0.048908,    0.045538,    0.044225,    0.043514,    0.042803,    0.041168,    0.039749,    0.038678,    0.035898,    0.035361,    0.034823,    0.034285,    0.033341,    0.032262,    0.031584,    0.030966,    0.030349,\n           0.029683,    0.028961,    0.028239,    0.027668,    0.027234,      0.0268,    0.026366,    0.025931,    0.023521,    0.023314,    0.023106,    0.022899,    0.022691,    0.022483,    0.022276,    0.022068,     0.02186,    0.021652,    0.020939,    0.019481,    0.019407,    0.019417,    0.019128,\n           0.018836,    0.018544,    0.018251,    0.017959,    0.017667,    0.017374,    0.016786,    0.016053,    0.015321,     0.01477,    0.014281,    0.013792,    0.013302,    0.012967,    0.012912,    0.012857,    0.012802,    0.012747,    0.012692,    0.012637,    0.012582,    0.012526,    0.012471,\n           0.012416,    0.012361,    0.012306,    0.012251,    0.012196,     0.01214,    0.012085,     0.01203,    0.011975,     0.01192,    0.011865,    0.011809,    0.011754,    0.011699,    0.011644,    0.011589,    0.011534,    0.011478,    0.011423,    0.011368,    0.011313,    0.011258,    0.011202,\n           0.011147,    0.011092,    0.011037,    0.010981,    0.010926,    0.010871,    0.010748,    0.010488,    0.010228,   0.0099675,   0.0097074,   0.0094472,   0.0091869,   0.0089265,   0.0086692,   0.0084847,   0.0083002,   0.0081156,    0.007931,   0.0077464,   0.0075617,    0.007377,   0.0071922,\n          0.0070074,   0.0068226,   0.0066378,   0.0064653,   0.0063173,   0.0061694,   0.0060214,   0.0058734,   0.0057254,   0.0055774,   0.0054293,   0.0052812,   0.0051331,    0.004985,   0.0048368,   0.0046887,   0.0045405,   0.0043923,   0.0043271,   0.0042974,   0.0042678,   0.0042381,   0.0042085,\n          0.0041788,   0.0041492,   0.0041195,   0.0040899,   0.0040602,   0.0040306,   0.0040009,   0.0039712,   0.0039416,   0.0039119,   0.0038823,   0.0038526,   0.0038229,   0.0037933,   0.0037636,    0.003734,   0.0037043,   0.0036746,    0.003645,   0.0036153,   0.0035856,    0.003556,   0.0035263,\n          0.0034966,   0.0034669,   0.0034373,   0.0034076,   0.0033779,   0.0033482,   0.0033186,   0.0032889,   0.0032592,   0.0032295,   0.0031998,   0.0031702,   0.0031405,   0.0031108,   0.0030811,   0.0030514,   0.0030218,   0.0029921,   0.0029624,   0.0029327,    0.002903,   0.0028733,   0.0028436,\n          0.0028139,   0.0027842,   0.0027545,   0.0027248,   0.0026952,   0.0026655,   0.0026358,   0.0026061,   0.0025764,   0.0025467,    0.002517,   0.0024873,   0.0024576,   0.0024279,   0.0023982,   0.0023685,   0.0023387,    0.002309,   0.0022793,   0.0022496,   0.0022199,   0.0021902,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.011672,    0.011672,    0.020168,    0.027657,    0.034479,    0.040736,    0.046734,    0.052242,    0.057413,    0.061829,    0.066823,    0.071151,    0.075286,    0.079697,    0.083395,    0.087454,    0.091359,    0.095335,    0.098055,     0.10138,     0.10518,     0.10913,     0.11207,\n             0.1153,     0.11822,     0.12069,     0.12358,     0.12639,      0.1292,     0.13207,     0.13548,     0.13812,     0.14099,     0.14376,     0.14652,     0.14914,     0.15185,     0.15457,     0.15758,     0.15977,     0.16269,     0.16519,     0.16685,     0.16844,     0.17016,     0.17308,\n            0.17469,     0.17736,     0.17926,     0.18119,      0.1827,      0.1848,     0.18668,     0.18834,     0.18962,     0.19248,     0.19469,     0.19672,     0.19854,     0.20063,     0.20167,     0.20373,     0.20531,     0.20629,     0.20806,     0.21039,     0.21297,     0.21392,      0.2175,\n            0.22069,     0.22238,     0.22463,     0.22662,     0.22856,     0.23022,     0.23208,     0.23384,     0.23561,      0.2383,     0.23834,     0.24014,      0.2416,     0.24401,     0.24526,     0.24708,     0.24813,     0.24965,     0.25137,     0.25187,     0.25307,     0.25584,     0.25734,\n            0.25855,     0.26042,      0.2616,     0.26259,      0.2642,     0.26412,      0.2668,     0.26856,        0.27,     0.27179,     0.27275,     0.27314,      0.2751,     0.27724,     0.27917,     0.28039,     0.28141,      0.2842,     0.28505,      0.2855,     0.28545,     0.28597,     0.28729,\n            0.28918,     0.29117,     0.29296,     0.29272,     0.29341,     0.29455,     0.29596,     0.29708,     0.29856,      0.2999,     0.30117,     0.30332,     0.30451,     0.30616,     0.30662,     0.30868,     0.31014,     0.31279,      0.3151,     0.31684,      0.3181,     0.31929,     0.31906,\n            0.31821,     0.31686,     0.31808,     0.32055,     0.32132,     0.32425,      0.3249,     0.32589,     0.32671,      0.3292,     0.33057,     0.33255,     0.33568,     0.33635,     0.33889,     0.33944,     0.34129,     0.34226,     0.34254,     0.34301,     0.34224,     0.34506,     0.34621,\n            0.34692,     0.34818,     0.34766,     0.34867,     0.34988,     0.35204,     0.35279,      0.3538,     0.35611,     0.35825,     0.36028,     0.36067,       0.363,      0.3651,     0.36595,     0.36731,     0.36733,     0.37094,     0.37221,     0.37482,     0.37692,     0.37784,     0.38007,\n            0.38225,      0.3845,     0.38509,     0.38437,     0.38415,     0.38477,     0.38661,     0.38809,     0.38648,     0.38856,     0.38839,     0.39012,     0.39217,     0.39312,      0.3953,      0.3958,     0.39838,     0.39809,     0.39781,     0.39828,     0.39865,     0.39972,     0.40013,\n            0.40047,     0.40321,     0.40616,     0.40915,     0.40836,     0.41044,     0.41097,     0.41244,     0.41211,     0.41314,     0.41451,     0.41622,     0.41837,     0.41799,     0.42173,     0.42373,     0.42455,     0.42629,     0.42914,     0.43115,     0.43258,     0.43397,     0.43429,\n            0.43532,     0.43611,      0.4367,     0.43481,     0.43509,     0.43658,     0.43695,     0.43863,     0.43804,     0.43918,     0.44183,     0.44586,     0.45083,     0.45137,     0.45155,     0.45092,     0.45381,     0.45413,     0.45569,     0.45852,     0.45939,     0.46054,     0.46135,\n            0.46369,      0.4628,     0.46692,       0.469,     0.47077,      0.4715,     0.47335,     0.47421,     0.47506,     0.47577,     0.47686,     0.47821,     0.48091,     0.48163,     0.48094,     0.48851,     0.48945,     0.49002,     0.49105,     0.48868,     0.49392,     0.49445,     0.49527,\n            0.49375,     0.49383,     0.49538,     0.49827,     0.49891,     0.50074,     0.50183,     0.50159,     0.50257,     0.50654,     0.50835,     0.50931,     0.50746,      0.5088,     0.51295,     0.51563,     0.51563,     0.51578,     0.51445,     0.51375,     0.51386,     0.51254,     0.51433,\n            0.51606,     0.51791,     0.52197,     0.52655,     0.53121,     0.53302,     0.53553,     0.53688,     0.53836,     0.53979,     0.53866,     0.54156,     0.53927,     0.53834,     0.53673,     0.54112,      0.5426,     0.54226,     0.54208,      0.5447,      0.5455,     0.54547,     0.54855,\n            0.54981,      0.5474,     0.55431,     0.55543,     0.55493,      0.5572,     0.56019,     0.56088,     0.55896,     0.55719,     0.55674,     0.55683,     0.55518,      0.5539,     0.56103,     0.56325,     0.56824,     0.56699,      0.5731,      0.5751,     0.57525,     0.57501,      0.5732,\n            0.57561,      0.5795,     0.58258,     0.58642,     0.59078,     0.59739,     0.59217,     0.59484,     0.59622,     0.59675,     0.59728,     0.59795,     0.59867,     0.59876,     0.59795,     0.59933,     0.60166,     0.59698,     0.59856,     0.60161,      0.6031,      0.6051,     0.60753,\n            0.61259,      0.6159,     0.61794,     0.61602,     0.61147,     0.61558,     0.61648,     0.61502,     0.61187,     0.60919,      0.6122,     0.61154,     0.61348,     0.61777,      0.6213,     0.62014,     0.61786,     0.61621,     0.61461,     0.61419,      0.6143,     0.61571,     0.62004,\n            0.61979,     0.61976,     0.61775,     0.62124,     0.62084,     0.63085,     0.63419,     0.63511,     0.63365,      0.6326,      0.6348,     0.63622,      0.6353,     0.63774,     0.63797,     0.64073,     0.63883,     0.63612,     0.63976,     0.63919,     0.64616,      0.6442,      0.6429,\n            0.64424,     0.64559,     0.64848,     0.65225,     0.65606,     0.66368,     0.67113,     0.67725,     0.67591,     0.67738,     0.68839,     0.69291,     0.69553,     0.70087,      0.7085,     0.71186,     0.71163,       0.721,      0.7236,     0.72985,     0.73381,     0.74002,     0.74139,\n            0.74008,     0.73909,     0.74098,     0.73894,     0.73665,     0.73961,     0.74096,     0.74506,     0.74929,     0.74904,     0.74797,     0.74758,     0.75603,     0.75527,     0.75255,     0.77129,     0.76679,     0.76436,     0.76146,     0.75864,     0.76128,     0.76392,     0.76914,\n            0.77732,     0.78566,     0.79419,      0.8029,     0.80705,     0.81158,      0.8125,     0.81144,     0.80744,     0.80061,     0.80725,     0.80772,     0.80627,     0.80507,     0.80916,     0.81425,     0.82298,     0.82066,     0.82564,      0.8311,     0.83004,     0.82708,     0.83094,\n            0.83011,     0.82929,     0.82574,     0.82075,     0.81982,     0.81889,     0.81785,     0.81642,     0.81456,     0.81653,     0.82492,     0.82348,     0.82202,     0.82053,     0.82166,     0.82633,       0.831,     0.82901,     0.82856,     0.83042,     0.83228,     0.83414,       0.836,\n            0.83786,     0.83972,     0.84158,     0.84107,     0.83962,     0.83813,     0.83664,     0.84285,     0.85079,     0.86612,       0.873,     0.87871,     0.88441,     0.88238,     0.87876,      0.8775,      0.8762,     0.87013,     0.87674,     0.88334,     0.88879,     0.88814,     0.88749,\n            0.88684,     0.88625,      0.8858,     0.88534,     0.88489,     0.88444,     0.88399,     0.88258,     0.88077,     0.88035,     0.87992,     0.87949,     0.87907,     0.87864,     0.87822,     0.87711,     0.87555,     0.87394,     0.87229,     0.86939,     0.88576,      0.8884,     0.88775,\n             0.8871,     0.88645,      0.8858,     0.88486,     0.88388,     0.88289,      0.8807,     0.89222,      0.9047,     0.90265,     0.90154,     0.90044,     0.91906,     0.93064,     0.93001,     0.92938,     0.92875,     0.92662,     0.92549,     0.92491,     0.92432,     0.92374,     0.92315,\n            0.92271,     0.92229,     0.92187,     0.92145,     0.92103,     0.92061,     0.92019,     0.91462,     0.91227,     0.91092,     0.90957,     0.90621,     0.90312,     0.90068,     0.89366,     0.89216,     0.89066,     0.88916,     0.93963,     0.93775,     0.93644,     0.93522,       0.934,\n             0.9326,     0.93097,     0.92934,     0.92798,     0.92685,     0.92573,      0.9246,     0.92347,     0.91619,     0.91545,     0.91471,     0.91397,     0.91323,     0.91249,     0.91175,     0.91101,     0.91027,     0.90953,     0.90657,     0.90036,     0.94827,     0.99952,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.76253,     0.76253,     0.73856,     0.72113,     0.70697,     0.69717,     0.68736,     0.67865,     0.66993,     0.66013,     0.65359,     0.64706,     0.63943,     0.63508,     0.62854,     0.62418,     0.62092,     0.61983,     0.61002,     0.60784,     0.60566,     0.60458,      0.6024,\n            0.59913,     0.59695,     0.59259,     0.58715,     0.58715,     0.58715,     0.58497,     0.58388,     0.57952,     0.57734,     0.57625,     0.57407,     0.57081,     0.56863,     0.56863,     0.56645,     0.56427,     0.56209,     0.55991,     0.55773,     0.55447,     0.55229,     0.55011,\n            0.54684,     0.54357,     0.54031,     0.53922,     0.53595,     0.53595,     0.53377,      0.5305,     0.52723,     0.52723,     0.52505,     0.52288,     0.52179,     0.52179,      0.5207,      0.5207,     0.51961,     0.51634,     0.51634,     0.51416,     0.51416,     0.51198,     0.51198,\n            0.51198,     0.51089,     0.51089,      0.5098,     0.50763,     0.50763,     0.50654,     0.50545,     0.50436,     0.50436,         0.5,         0.5,         0.5,         0.5,     0.49891,     0.49891,     0.49673,     0.49564,     0.49564,     0.49129,     0.48911,     0.48911,     0.48802,\n            0.48802,     0.48802,     0.48742,     0.48584,     0.48423,     0.48039,     0.48039,     0.48039,     0.48039,      0.4793,     0.47821,     0.47712,     0.47712,     0.47495,     0.47386,     0.47277,     0.47277,     0.47277,     0.47166,      0.4695,     0.46623,     0.46405,     0.46296,\n            0.46296,     0.46187,     0.46187,     0.45861,     0.45752,     0.45643,     0.45534,     0.45534,     0.45425,     0.45425,     0.45207,     0.45098,     0.44989,      0.4488,     0.44771,     0.44771,     0.44771,     0.44662,     0.44662,     0.44508,     0.44336,     0.44118,     0.43997,\n            0.43682,     0.43251,     0.43137,     0.43137,     0.43028,     0.43028,     0.42919,     0.42919,      0.4281,      0.4281,      0.4281,      0.4281,      0.4281,     0.42702,     0.42702,     0.42702,     0.42375,     0.42266,     0.41939,     0.41915,     0.41612,     0.41612,     0.41503,\n            0.41394,     0.41394,     0.41176,     0.40959,      0.4085,     0.40837,     0.40741,     0.40632,     0.40632,     0.40414,     0.40414,     0.40305,     0.40305,     0.40305,     0.40087,     0.40087,     0.39978,     0.39869,      0.3976,      0.3976,      0.3976,     0.39628,     0.39434,\n            0.39434,     0.39434,     0.39294,     0.38889,     0.38799,     0.38671,     0.38562,     0.38562,     0.38235,     0.38212,     0.38017,     0.38017,     0.38017,     0.38017,     0.38017,     0.37908,     0.37798,     0.37464,     0.37364,      0.3735,     0.37146,     0.37037,     0.36819,\n             0.3671,      0.3671,      0.3671,      0.3671,     0.36492,     0.36383,     0.36275,     0.36275,     0.36057,     0.35948,     0.35948,     0.35839,     0.35839,     0.35621,     0.35621,     0.35621,     0.35621,     0.35403,     0.35403,     0.35403,     0.35403,     0.35403,     0.35294,\n            0.35185,     0.35076,     0.34641,     0.34314,     0.34096,     0.33987,     0.33769,     0.33535,     0.33285,     0.33115,     0.33007,     0.33007,     0.32998,     0.32801,     0.32646,     0.32353,     0.32353,     0.32135,     0.32026,     0.32026,     0.32026,     0.32026,     0.32026,\n            0.31917,     0.31699,     0.31699,     0.31699,     0.31699,      0.3159,     0.31481,     0.31373,     0.31151,     0.30937,     0.30937,     0.30849,     0.30828,     0.30769,      0.3061,     0.30588,     0.30501,     0.30283,     0.30058,     0.29672,     0.29521,     0.29521,     0.29502,\n            0.29323,      0.2912,     0.28873,     0.28867,     0.28867,     0.28867,      0.2875,     0.28649,     0.28649,      0.2854,      0.2854,     0.28493,     0.28214,     0.28105,     0.28105,     0.28064,     0.27947,     0.27887,      0.2756,     0.27233,     0.27174,     0.26916,     0.26906,\n            0.26797,     0.26797,     0.26797,     0.26797,     0.26785,     0.26688,     0.26688,     0.26688,     0.26688,     0.26448,     0.26328,     0.26252,      0.2601,     0.25913,     0.25599,     0.25599,     0.25457,     0.25381,     0.25163,     0.25163,     0.25102,     0.25054,     0.24946,\n            0.24878,     0.24637,      0.2451,      0.2451,     0.24312,     0.24183,     0.24183,     0.24074,     0.23746,     0.23577,     0.23312,     0.22858,      0.2257,     0.22453,      0.2244,     0.22004,     0.21895,     0.21681,     0.21569,     0.21569,      0.2146,     0.21224,     0.21067,\n            0.20806,     0.20717,     0.20588,     0.20543,      0.2037,     0.20043,     0.19608,     0.19499,     0.19463,      0.1939,     0.19225,     0.19172,     0.19063,     0.19019,     0.18955,     0.18627,     0.18627,     0.18233,     0.18083,     0.18083,     0.18083,     0.17974,     0.17874,\n            0.17756,     0.17647,     0.17619,     0.17476,     0.17144,     0.16921,      0.1681,     0.16706,     0.16486,     0.16132,     0.15993,     0.15948,     0.15904,     0.15795,     0.15795,      0.1565,     0.15499,     0.15391,     0.15288,     0.15142,     0.15033,     0.15033,     0.15033,\n            0.14916,     0.14815,     0.14597,     0.14472,     0.14379,     0.14334,      0.1427,      0.1422,     0.14131,     0.14067,     0.14052,     0.13943,     0.13852,     0.13834,     0.13629,     0.13617,     0.13487,      0.1329,     0.13155,     0.13072,     0.13072,      0.1282,     0.12527,\n            0.12527,     0.12527,     0.12527,     0.12527,     0.12527,     0.12309,     0.12227,     0.12115,     0.12041,     0.11874,     0.11765,     0.11765,     0.11656,     0.11438,     0.11329,     0.11303,      0.1122,      0.1122,      0.1122,     0.11183,     0.11002,     0.11002,      0.1093,\n            0.10856,       0.108,     0.10595,     0.10484,      0.1024,      0.1024,     0.10022,    0.099129,    0.098039,    0.097543,    0.096985,    0.093682,    0.091145,    0.090773,    0.089325,    0.088169,    0.085963,    0.084806,    0.083457,    0.081699,    0.081699,    0.081699,    0.081699,\n           0.081699,    0.081699,    0.081699,    0.081699,     0.08061,     0.08061,     0.08025,    0.079691,    0.077656,    0.074361,    0.074074,    0.073217,    0.072543,    0.071984,    0.071895,    0.071895,    0.070902,    0.069785,    0.069717,    0.069717,    0.069166,    0.067538,    0.064248,\n           0.063875,    0.063503,    0.061942,    0.059854,    0.059482,     0.05911,    0.058694,    0.058136,    0.057421,    0.056645,    0.056461,    0.055903,    0.055345,    0.054786,    0.054466,    0.054466,    0.054466,    0.052819,    0.052288,    0.052288,    0.052288,    0.052288,    0.052288,\n           0.052288,    0.052288,    0.052288,    0.051886,    0.051327,    0.050769,    0.050211,    0.050109,    0.050109,    0.050109,    0.050109,    0.050109,    0.050109,    0.049033,    0.047379,     0.04682,    0.046262,    0.043573,    0.043573,    0.043573,    0.043529,    0.043249,     0.04297,\n           0.042691,    0.042436,     0.04225,    0.042064,    0.041878,    0.041691,    0.041505,    0.040944,    0.040237,    0.040077,    0.039918,    0.039758,    0.039599,    0.039439,     0.03928,    0.038881,    0.038323,    0.037765,    0.037207,     0.03626,    0.035948,    0.034692,    0.034469,\n           0.034245,    0.034022,    0.033799,    0.033492,    0.033173,    0.032854,    0.032174,     0.03159,     0.03103,    0.030305,    0.029933,    0.029561,    0.029412,    0.029238,    0.028959,    0.028679,      0.0284,    0.027517,    0.027067,    0.026843,     0.02662,    0.026397,    0.026173,\n           0.026015,    0.025866,    0.025717,    0.025568,    0.025419,     0.02527,    0.025121,     0.02335,    0.022662,     0.02229,    0.021917,    0.021062,    0.020322,    0.019763,    0.018317,    0.018038,    0.017759,     0.01748,    0.016972,    0.016413,    0.016063,    0.015744,    0.015425,\n           0.015082,     0.01471,    0.014337,    0.014044,     0.01382,    0.013597,    0.013374,     0.01315,    0.011914,    0.011807,    0.011701,    0.011595,    0.011488,    0.011382,    0.011276,    0.011169,    0.011063,    0.010956,    0.010592,   0.0098472,   0.0098039,   0.0098039,   0.0096564,\n          0.0095075,   0.0093587,   0.0092098,   0.0090609,    0.008912,   0.0087632,   0.0084638,   0.0080916,   0.0077194,   0.0074399,   0.0071918,   0.0069436,   0.0066955,    0.006526,   0.0064981,   0.0064702,   0.0064422,   0.0064143,   0.0063864,   0.0063585,   0.0063306,   0.0063027,   0.0062748,\n          0.0062468,   0.0062189,    0.006191,   0.0061631,   0.0061352,   0.0061073,   0.0060794,   0.0060514,   0.0060235,   0.0059956,   0.0059677,   0.0059398,   0.0059119,   0.0058839,    0.005856,   0.0058281,   0.0058002,   0.0057723,   0.0057444,   0.0057165,   0.0056885,   0.0056606,   0.0056327,\n          0.0056048,   0.0055769,    0.005549,   0.0055211,   0.0054931,   0.0054652,   0.0054028,   0.0052715,   0.0051401,   0.0050087,   0.0048774,    0.004746,   0.0046146,   0.0044833,   0.0043535,   0.0042604,   0.0041674,   0.0040743,   0.0039813,   0.0038882,   0.0037952,   0.0037021,   0.0036091,\n           0.003516,    0.003423,   0.0033299,   0.0032431,   0.0031687,   0.0030942,   0.0030198,   0.0029454,   0.0028709,   0.0027965,    0.002722,   0.0026476,   0.0025732,   0.0024987,   0.0024243,   0.0023498,   0.0022754,    0.002201,   0.0021682,   0.0021533,   0.0021384,   0.0021236,   0.0021087,\n          0.0020938,   0.0020789,    0.002064,   0.0020491,   0.0020342,   0.0020193,   0.0020045,   0.0019896,   0.0019747,   0.0019598,   0.0019449,     0.00193,   0.0019151,   0.0019002,   0.0018854,   0.0018705,   0.0018556,   0.0018407,   0.0018258,   0.0018109,    0.001796,   0.0017811,   0.0017663,\n          0.0017514,   0.0017365,   0.0017216,   0.0017067,   0.0016918,   0.0016769,    0.001662,   0.0016472,   0.0016323,   0.0016174,   0.0016025,   0.0015876,   0.0015727,   0.0015578,   0.0015429,    0.001528,   0.0015132,   0.0014983,   0.0014834,   0.0014685,   0.0014536,   0.0014387,   0.0014238,\n          0.0014089,   0.0013941,   0.0013792,   0.0013643,   0.0013494,   0.0013345,   0.0013196,   0.0013047,   0.0012898,    0.001275,   0.0012601,   0.0012452,   0.0012303,   0.0012154,   0.0012005,   0.0011856,   0.0011707,   0.0011559,    0.001141,   0.0011261,   0.0011112,   0.0010963,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\nfitness: np.float64(0.15659161499064395)\nkeys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\nmaps: array([    0.15659])\nnames: {0: 'ball'}\nnt_per_class: array([918])\nnt_per_image: array([491])\nresults_dict: {'metrics/precision(B)': 0.40915319287719576, 'metrics/recall(B)': 0.3671023965141612, 'metrics/mAP50(B)': 0.3058356028653723, 'metrics/mAP50-95(B)': 0.15659161499064395, 'fitness': 0.15659161499064395}\nsave_dir: PosixPath('/kaggle/working/runs/detect/train')\nspeed: {'preprocess': 0.08597085336083282, 'inference': 0.7746458533613132, 'loss': 0.0003283075344637181, 'postprocess': 1.078996364561537}\nstats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\ntask: 'detect'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# fine tuning\n!yolo detect train \\\n  model=/kaggle/working/runs/detect/train/weights/best.pt \\\n  data=/kaggle/working/data.yaml \\\n  epochs=50 \\\n  imgsz=640 \\\n  batch=16 \\\n  lr0=0.001 \\\n  patience=20","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:47:36.028828Z","iopub.execute_input":"2026-01-06T02:47:36.029440Z","iopub.status.idle":"2026-01-06T03:10:19.955792Z","shell.execute_reply.started":"2026-01-06T02:47:36.029395Z","shell.execute_reply":"2026-01-06T03:10:19.954700Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.248 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/working/runs/detect/train/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \nModel summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n\nTransferred 355/355 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3795.1¬±920.5 MB/s, size: 274.9 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/labels/train.cache... 2097 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2097/2097 29.5Mit/s 0.0ss\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 912.6¬±951.7 MB/s, size: 248.0 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/labels/val.cache... 491 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 491/491 3.7Mit/s 0.0ss\nPlotting labels to /kaggle/working/runs/detect/train2/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 4 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/train2\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/50      2.38G       1.82      2.473      2.273          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 4.1it/s 32.6s0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.1it/s 2.6s0.2s\n                   all        491        918      0.337      0.252      0.202     0.0701\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/50      2.87G      1.729      2.457       2.18          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.4it/s 24.4s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.4s0.2s\n                   all        491        918      0.258      0.229      0.162     0.0628\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/50      2.87G      1.756      2.544      2.212          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.263      0.248      0.144     0.0531\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/50      2.89G      1.748      2.542       2.23          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.4s0.2s\n                   all        491        918      0.271      0.239      0.164     0.0658\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/50       2.9G      1.757      2.542      2.214          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.3it/s 2.5s0.2s\n                   all        491        918      0.252      0.263      0.156     0.0528\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/50       2.9G      1.736      2.548      2.206          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.4s0.2s\n                   all        491        918      0.259      0.247      0.169     0.0619\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/50       2.9G      1.705      2.502      2.181          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.244      0.235      0.157     0.0561\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/50       2.9G      1.709      2.525      2.175          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.1it/s 2.6s0.2s\n                   all        491        918      0.259      0.253      0.155     0.0556\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/50      2.92G      1.711      2.519      2.193          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.282      0.237      0.171     0.0603\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/50      2.94G      1.681      2.484      2.156          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.5s0.2s\n                   all        491        918      0.252      0.255      0.151     0.0553\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      11/50      2.94G      1.662      2.456      2.143          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.325      0.277      0.195      0.078\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      12/50      2.94G      1.686      2.483      2.158          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.5s0.2s\n                   all        491        918      0.288      0.266      0.188     0.0754\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      13/50      2.94G      1.685      2.524      2.148          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 24.2s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.6it/s 2.4s0.2s\n                   all        491        918      0.334      0.279      0.222      0.097\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      14/50      2.94G      1.669      2.463      2.145          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.278      0.283      0.193     0.0798\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      15/50      2.94G       1.66      2.464      2.138         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.322      0.278        0.2     0.0874\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      16/50      2.94G       1.65      2.439      2.131          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.289      0.275      0.195     0.0849\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      17/50      2.94G      1.641      2.428      2.115          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.1it/s 2.6s0.2s\n                   all        491        918      0.297      0.271      0.196     0.0834\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      18/50      2.94G      1.633      2.396      2.111          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.3it/s 2.5s0.2s\n                   all        491        918      0.341       0.28      0.216     0.0963\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      19/50      2.94G      1.617      2.378      2.097          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 24.0s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.334      0.275      0.216     0.0927\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      20/50      2.94G      1.612       2.39      2.093          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.3it/s 2.6s0.2s\n                   all        491        918      0.357      0.283      0.218     0.0936\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      21/50      2.94G      1.595      2.362      2.082          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.7s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.313      0.288      0.212     0.0866\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      22/50      2.94G      1.594      2.367      2.088          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 24.0s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.3it/s 2.5s0.2s\n                   all        491        918      0.334       0.28      0.232        0.1\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      23/50      2.94G      1.601      2.334      2.089          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.323      0.272      0.219     0.0934\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      24/50      2.94G      1.585      2.346      2.079          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.4s0.2s\n                   all        491        918      0.306      0.282      0.216      0.097\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      25/50      2.94G      1.595       2.34      2.076          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.3it/s 2.5s0.2s\n                   all        491        918      0.315      0.313      0.204     0.0917\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      26/50      2.94G      1.599      2.326      2.073         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.356      0.309      0.235      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      27/50      2.94G      1.564      2.328      2.049          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.5s0.2s\n                   all        491        918      0.336      0.293      0.225      0.102\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      28/50      3.26G      1.565      2.291      2.055          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.5s0.2s\n                   all        491        918      0.335      0.305      0.256      0.121\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      29/50      3.26G      1.566      2.289      2.061          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.307      0.317       0.22     0.0992\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      30/50      3.26G      1.577      2.352      2.039          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.5s0.2s\n                   all        491        918      0.327      0.339      0.232      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      31/50      3.26G      1.552      2.301      2.037          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.3it/s 2.5s0.2s\n                   all        491        918      0.304      0.327      0.222     0.0898\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      32/50      3.26G      1.565      2.299      2.058          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.3it/s 2.5s0.2s\n                   all        491        918      0.328      0.304      0.227      0.104\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      33/50      3.26G      1.563      2.303      2.044          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 24.0s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.4s0.2s\n                   all        491        918      0.345      0.318      0.243      0.114\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      34/50      3.26G      1.534      2.242      2.023          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.6it/s 2.4s0.2s\n                   all        491        918       0.33      0.336      0.238       0.11\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      35/50      3.26G      1.538      2.255      2.002          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.342      0.332      0.244      0.107\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      36/50      3.26G      1.529      2.245      2.014          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.8s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.327       0.34      0.242      0.106\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      37/50      3.27G      1.529      2.195      2.011         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.5s0.2s\n                   all        491        918      0.351      0.369      0.267      0.122\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      38/50      3.28G      1.498      2.214      1.981          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.3it/s 2.5s0.2s\n                   all        491        918      0.351      0.336      0.256      0.116\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      39/50      3.28G      1.518      2.225      2.007          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 23.9s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.5it/s 2.5s0.2s\n                   all        491        918      0.338      0.344      0.257      0.118\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      40/50      3.28G      1.499      2.223      1.986          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.5it/s 24.1s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.6it/s 2.4s0.2s\n                   all        491        918       0.34      0.351      0.268      0.127\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      41/50      3.28G      1.424      2.125      1.987          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.2it/s 25.2s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.6it/s 2.4s0.2s\n                   all        491        918      0.344      0.375      0.272      0.131\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      42/50      3.28G      1.334      1.907      1.911          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.6s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.381      0.377      0.298       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      43/50      3.28G      1.324      1.864        1.9         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.4s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.7it/s 2.4s0.2s\n                   all        491        918      0.344      0.369      0.273      0.131\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      44/50      3.28G      1.303      1.837      1.898          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.5s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.3it/s 2.5s0.2s\n                   all        491        918      0.384      0.357      0.274      0.132\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      45/50      3.28G      1.305      1.817      1.882          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.6s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.6it/s 2.4s0.2s\n                   all        491        918      0.379      0.346      0.277      0.138\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      46/50      3.28G       1.28      1.769      1.864          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.6s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.6it/s 2.4s0.2s\n                   all        491        918      0.387      0.365      0.296      0.146\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      47/50      3.28G       1.28      1.755      1.858          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.5s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918      0.384      0.386      0.301       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      48/50      3.28G      1.256      1.739      1.844          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.5s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.6it/s 2.4s0.2s\n                   all        491        918      0.398      0.385      0.296       0.15\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      49/50      3.28G      1.252      1.739      1.832          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.5s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.7it/s 2.4s0.2s\n                   all        491        918      0.376      0.392      0.299      0.151\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      50/50      3.28G      1.252       1.74      1.837          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 5.6it/s 23.5s0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 6.4it/s 2.5s0.2s\n                   all        491        918       0.39      0.386      0.301      0.154\n\n50 epochs completed in 0.372 hours.\nOptimizer stripped from /kaggle/working/runs/detect/train2/weights/last.pt, 6.2MB\nOptimizer stripped from /kaggle/working/runs/detect/train2/weights/best.pt, 6.2MB\n\nValidating /kaggle/working/runs/detect/train2/weights/best.pt...\nUltralytics 8.3.248 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nModel summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 16/16 5.2it/s 3.1s0.2s\n                   all        491        918      0.389      0.386      0.301      0.154\nSpeed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 1.6ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/train2\u001b[0m\nüí° Learn more at https://docs.ultralytics.com/modes/train\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# eexport to onnx\n!yolo export \\\n  model=/kaggle/working/runs/detect/train2/weights/best.pt \\\n  format=onnx \\\n  imgsz=640","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:42:36.885624Z","iopub.execute_input":"2026-01-06T03:42:36.886399Z","iopub.status.idle":"2026-01-06T03:42:43.332156Z","shell.execute_reply.started":"2026-01-06T03:42:36.886328Z","shell.execute_reply":"2026-01-06T03:42:43.331434Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.248 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\nüí° ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\nModel summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/kaggle/working/runs/detect/train2/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.9 MB)\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxslim>=0.1.71', 'onnxruntime'] not found, attempting AutoUpdate...\nUsing Python 3.12.12 environment at: /usr\nResolved 14 packages in 225ms\nPrepared 4 packages in 232ms\nInstalled 4 packages in 12ms\n + coloredlogs==15.0.1\n + humanfriendly==10.0\n + onnxruntime==1.23.2\n + onnxslim==0.1.82\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 0.8s\nWARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.0 opset 22...\n/usr/local/lib/python3.12/dist-packages/torch/onnx/utils.py:1397: OnnxExporterWarning: Exporting to ONNX opset version 22 is not supported. by 'torch.onnx.export()'. The highest opset version supported is 20. To use a newer opset version, consider 'torch.onnx.export(..., dynamo=True)'. \n  warnings.warn(\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 2.1s, saved as '/kaggle/working/runs/detect/train2/weights/best.onnx' (11.7 MB)\n\nExport complete (2.5s)\nResults saved to \u001b[1m/kaggle/working/runs/detect/train2/weights\u001b[0m\nPredict:         yolo predict task=detect model=/kaggle/working/runs/detect/train2/weights/best.onnx imgsz=640  \nValidate:        yolo val task=detect model=/kaggle/working/runs/detect/train2/weights/best.onnx imgsz=640 data=/kaggle/working/data.yaml  \nVisualize:       https://netron.app\nüí° Learn more at https://docs.ultralytics.com/modes/export\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# export onnx to tensorflow\n!yolo export \\\n  model=/kaggle/working/runs/detect/train2/weights/best.pt \\\n  format=tf \\\n  imgsz=640","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:43:20.641440Z","iopub.execute_input":"2026-01-06T03:43:20.642107Z","iopub.status.idle":"2026-01-06T03:44:02.898231Z","shell.execute_reply.started":"2026-01-06T03:43:20.642069Z","shell.execute_reply":"2026-01-06T03:44:02.897498Z"}},"outputs":[{"name":"stdout","text":"WARNING ‚ö†Ô∏è Invalid export format='tf', updating to format='tfjs'\nUltralytics 8.3.248 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\nModel summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/kaggle/working/runs/detect/train2/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.9 MB)\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767671005.732260     422 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767671005.784782     422 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767671006.187400     422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767671006.187451     422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767671006.187456     422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767671006.187459     422 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0', 'onnx2tf>=1.26.3'] not found, attempting AutoUpdate...\nUsing Python 3.12.12 environment at: /usr\nResolved 12 packages in 2.29s\nPrepared 5 packages in 137ms\nInstalled 5 packages in 8ms\n + ai-edge-litert==2.1.0\n + backports-strenum==1.3.1\n + onnx-graphsurgeon==0.5.8\n + onnx2tf==1.28.8\n + sng4onnx==1.0.4\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 2.6s\nWARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\n\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.0 opset 22...\n/usr/local/lib/python3.12/dist-packages/torch/onnx/utils.py:1397: OnnxExporterWarning: Exporting to ONNX opset version 22 is not supported. by 'torch.onnx.export()'. The highest opset version supported is 20. To use a newer opset version, consider 'torch.onnx.export(..., dynamo=True)'. \n  warnings.warn(\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.0s, saved as '/kaggle/working/runs/detect/train2/weights/best.onnx' (11.7 MB)\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.1MB 39.0MB/s 0.0s\n\u001b[KUnzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /kaggle/working/calibration_image_sample_data_20x128x128x3_float32.npy...: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 52.6files/s 0.0s\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.8...\nSaved artifact at '/kaggle/working/runs/detect/train2/weights/best_saved_model'. The following endpoints are available:\n\n* Endpoint 'serving_default'\n  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\nOutput Type:\n  TensorSpec(shape=(1, 5, 8400), dtype=tf.float32, name=None)\nCaptures:\n  133218843035216: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  133218843034256: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n  133218843034640: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  133218843038672: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  133218843039824: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n  133218843039440: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  133218843040016: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n  133218843040208: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  133218843041168: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218843040784: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218843043088: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n  133218843043664: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  133218843040400: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n  133218843036176: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  133218843041744: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218843041360: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218843043856: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n  133218843044432: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  133218843042704: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  133218843044816: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n  133218843042512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218843045008: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  133218843044624: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218843045968: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218843045200: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218843046352: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  133218843047312: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  133218843043280: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  133218843044048: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  133218843046544: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  133218843047504: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  133218843044240: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  133218843047888: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  133218843045392: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218843045776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218843048272: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  133218843047696: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218843048464: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  133218843046736: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n  133218843048080: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218843048848: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  133218843049040: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218686337680: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686338064: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218843049424: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218843048656: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218843049616: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218843049232: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686338640: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218686339024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686338832: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218686339408: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218843049808: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686337104: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686339792: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n  133218686339216: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218686339984: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  133218686338256: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n  133218686339600: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  133218686340368: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n  133218686340560: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  133218686341136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686340944: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686343056: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  133218686343248: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218686340752: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  133218686340176: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218686341328: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686341520: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686343440: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  133218686342096: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  133218686342480: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n  133218686343824: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218686342672: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n  133218686343632: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  133218686344592: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n  133218686344784: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218686345168: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686344400: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686346512: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218686346704: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686344976: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218686344016: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686345936: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686344208: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686347472: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  133218686347280: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218686346128: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n  133218686346320: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686348048: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686347856: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686349968: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  133218686350160: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  133218686347664: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  133218686345744: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  133218686348240: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686348432: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218686350544: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n  133218686350352: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686350736: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  133218686349392: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218686349008: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686352656: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  133218686352080: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218684518864: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218684518672: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218684521360: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218684521552: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684519056: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218684521936: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684519248: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218684519440: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218684520976: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  133218684520400: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218684522128: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  133218684518480: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  133218684520016: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218684521744: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  133218684523280: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  133218684524816: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218684524624: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218684525200: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  133218684525968: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218684527312: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  133218684527888: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  133218684525392: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218684525776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  133218684526928: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  133218684528080: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  133218684527696: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n  133218684527120: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n  133218684522512: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n  133218684521168: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n  133218686351504: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218686351120: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218684523472: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684527504: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684522320: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684522896: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686349584: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686350928: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684528656: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218684526544: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218684523664: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218684520592: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218686352272: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218686351312: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  133218684528272: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684528464: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684522704: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684523088: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686351888: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686351696: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684529424: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n  133218684528848: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  133218684525008: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n  133218684524240: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  133218686352848: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n  133218686353040: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  133218684529232: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684529040: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n  133218684524048: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218684523856: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n  133218686352464: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  133218686353232: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n  133218684530384: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n  133218684530000: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  133218684530960: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  133218684529616: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  133218684531920: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  133218684532112: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n  133218684533072: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\nI0000 00:00:1767671030.405215     422 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1767671030.405398     422 single_machine.cc:374] Starting new session\nW0000 00:00:1767671031.123106     422 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1767671031.123154     422 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nI0000 00:00:1767671031.884503     422 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\nI0000 00:00:1767671031.884679     422 single_machine.cc:374] Starting new session\nW0000 00:00:1767671032.449098     422 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1767671032.449137     422 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 29.0s, saved as '/kaggle/working/runs/detect/train2/weights/best_saved_model' (29.3 MB)\n\n\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m starting export with tensorflow 2.19.0...\nI0000 00:00:1767671033.455390     422 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\nI0000 00:00:1767671033.455553     422 single_machine.cc:374] Starting new session\n\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m export success ‚úÖ 1.0s, saved as '/kaggle/working/runs/detect/train2/weights/best.pb' (11.7 MB)\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['tensorflowjs'] not found, attempting AutoUpdate...\nUsing Python 3.12.12 environment at: /usr\nResolved 67 packages in 439ms\nPrepared 2 packages in 28ms\nUninstalled 1 package in 4ms\nInstalled 2 packages in 4ms\n - packaging==25.0\n + packaging==23.2\n + tensorflowjs==4.22.0\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 0.6s\nWARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\n\u001b[32müå≤ Try \u001b[0m\u001b[34mhttps://ydf.readthedocs.io\u001b[0m\u001b[32m, the successor of TensorFlow Decision Forests with more features and faster training!\u001b[0m\n\n\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m starting export with tensorflowjs 4.22.0...\n\n\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m output node names: Identity:0\n\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m running 'tensorflowjs_converter --input_format=tf_frozen_model  --output_node_names=Identity:0 \"/kaggle/working/runs/detect/train2/weights/best.pb\" \"/kaggle/working/runs/detect/train2/weights/best_web_model\"'\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767671035.856259     512 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767671035.862206     512 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767671035.878060     512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767671035.878088     512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767671035.878092     512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767671035.878095     512 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n\u001b[32müå≤ Try \u001b[0m\u001b[34mhttps://ydf.readthedocs.io\u001b[0m\u001b[32m, the successor of TensorFlow Decision Forests with more features and faster training!\u001b[0m\nweight model_13/tf.strided_slice_19/ones_like/tensor with shape (3,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_19/StridedSlice/end with shape (3,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_19/ones_like with shape (3,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_18/ones_like/tensor with shape (3,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_18/StridedSlice/end with shape (3,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_18/ones_like with shape (3,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_14/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_14/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_14/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_12/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_12/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_12/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_10/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_10/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_10/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_11/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_11/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_11/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_8/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_8/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_8/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_9/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_9/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_9/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_13/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_13/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_13/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_6/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_6/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_6/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_4/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_4/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_4/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_2/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_2/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_2/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_1/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_1/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_1/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_3/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_3/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_3/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_5/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_5/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_5/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_7/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_7/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_7/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_15/ones_like/tensor with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_15/StridedSlice/end with shape (4,) and dtype int64 was auto converted to the type int32\nweight model_13/tf.strided_slice_15/ones_like with shape (4,) and dtype int64 was auto converted to the type int32\n\u001b[34m\u001b[1mTensorFlow.js:\u001b[0m export success ‚úÖ 6.9s, saved as '/kaggle/working/runs/detect/train2/weights/best_web_model' (11.8 MB)\n\nExport complete (37.2s)\nResults saved to \u001b[1m/kaggle/working/runs/detect/train2/weights\u001b[0m\nPredict:         yolo predict task=detect model=/kaggle/working/runs/detect/train2/weights/best_web_model imgsz=640  \nValidate:        yolo val task=detect model=/kaggle/working/runs/detect/train2/weights/best_web_model imgsz=640 data=/kaggle/working/data.yaml  \nVisualize:       https://netron.app\nüí° Learn more at https://docs.ultralytics.com/modes/export\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# export to tflite\n!yolo export \\\n  model=/kaggle/working/runs/detect/train2/weights/best.pt \\\n  format=tflite \\\n  imgsz=640","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:45:52.883547Z","iopub.execute_input":"2026-01-06T03:45:52.884472Z","iopub.status.idle":"2026-01-06T03:46:12.480076Z","shell.execute_reply.started":"2026-01-06T03:45:52.884421Z","shell.execute_reply":"2026-01-06T03:46:12.479310Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.248 üöÄ Python-3.12.12 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.00GHz)\nModel summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n\n\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/kaggle/working/runs/detect/train2/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (5.9 MB)\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767671156.694753     556 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767671156.701082     556 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767671156.718725     556 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767671156.718753     556 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767671156.718758     556 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767671156.718766     556 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n\n\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.0 opset 22...\n/usr/local/lib/python3.12/dist-packages/torch/onnx/utils.py:1397: OnnxExporterWarning: Exporting to ONNX opset version 22 is not supported. by 'torch.onnx.export()'. The highest opset version supported is 20. To use a newer opset version, consider 'torch.onnx.export(..., dynamo=True)'. \n  warnings.warn(\n\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.82...\n\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 1.2s, saved as '/kaggle/working/runs/detect/train2/weights/best.onnx' (11.8 MB)\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.8...\nSaved artifact at '/kaggle/working/runs/detect/train2/weights/best_saved_model'. The following endpoints are available:\n\n* Endpoint 'serving_default'\n  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\nOutput Type:\n  TensorSpec(shape=(1, 5, 8400), dtype=tf.float32, name=None)\nCaptures:\n  137173160345040: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  137173160344848: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n  137173138637264: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  137173138637840: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  137173138637072: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n  137173138641488: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  137173138642448: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n  137173138641872: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  137173138643024: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173138642832: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173138645328: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n  137173138645712: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  137173138642640: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n  137173138639568: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n  137173138643216: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173138643408: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173138643984: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n  137173138644368: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  137173138644560: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  137173138645904: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n  137173138646288: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173138646672: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  137173138646864: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173138647440: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173138647248: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173138649360: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  137173138649552: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  137173138647056: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  137173138646480: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  137173138648784: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  137173138649744: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  137173138648400: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  137173138650128: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  137173138647632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173138647824: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173138650512: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n  137173138649936: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173138650704: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  137173138648976: TensorSpec(shape=(3, 3, 64, 128), dtype=tf.float32, name=None)\n  137173138650320: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173138651088: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n  137173138651280: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173138651856: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173138651664: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173138651472: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173138652816: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173138650896: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173138652432: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173138652624: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173007779024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007778064: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173007778832: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173138652048: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173138652240: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007779600: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n  137173007778640: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173007779792: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  137173007779216: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n  137173007779408: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  137173007780176: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n  137173007780368: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  137173007780944: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007780752: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007782864: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  137173007783056: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173007780560: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  137173007779984: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173007781136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007781328: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007783248: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  137173007781904: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  137173007782288: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n  137173007783632: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173007783824: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n  137173007784016: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  137173007784400: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n  137173007784208: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173007784784: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007784592: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007786704: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173007786896: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007782480: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173007783440: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007784976: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007785168: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007787280: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  137173007787088: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173007786320: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n  137173007786128: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007787856: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007787664: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007789776: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  137173007789968: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  137173007787472: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n  137173007785744: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n  137173007788048: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007788240: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007790352: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n  137173007790160: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007790544: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  137173007789200: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173007788816: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007792464: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  137173007791888: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173006008976: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173006009360: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173007793040: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173007793424: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007793808: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173007793616: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007794000: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173006008400: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173006010704: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n  137173006010896: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173006010512: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n  137173006009552: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  137173006009936: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173006012624: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  137173006012048: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  137173006013776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173006013584: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173006013968: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  137173006014928: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173006016272: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n  137173006016848: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n  137173006014160: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173006014352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n  137173006015888: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n  137173006017040: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n  137173006016656: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n  137173006016080: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n  137173006011472: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n  137173006011088: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n  137173007791312: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173007790928: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173006013200: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173006016464: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173006010128: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173006010320: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007789392: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007790736: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173006017616: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173006015504: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173006012240: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173006011280: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173007792080: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173007791120: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n  137173006017232: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173006017424: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173006011856: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173006011664: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007791696: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007791504: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173006018384: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n  137173006017808: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  137173006013392: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n  137173006013008: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  137173007793232: TensorSpec(shape=(1, 1, 64, 1), dtype=tf.float32, name=None)\n  137173007792848: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n  137173006018192: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173006018000: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n  137173006012432: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173006012816: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n  137173007792272: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n  137173007792656: TensorSpec(shape=(1,), dtype=tf.float32, name=None)\n  137173006019152: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n  137173006018768: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  137173006020496: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  137173006019920: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  137173006019728: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n  137173006021072: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n  137173006020880: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\nI0000 00:00:1767671168.312094     556 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1767671168.312272     556 single_machine.cc:374] Starting new session\nW0000 00:00:1767671168.931257     556 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1767671168.931293     556 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nI0000 00:00:1767671169.546724     556 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\nI0000 00:00:1767671169.546913     556 single_machine.cc:374] Starting new session\nW0000 00:00:1767671170.110921     556 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1767671170.110953     556 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success ‚úÖ 14.4s, saved as '/kaggle/working/runs/detect/train2/weights/best_saved_model' (29.5 MB)\n\n\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success ‚úÖ 0.0s, saved as '/kaggle/working/runs/detect/train2/weights/best_saved_model/best_float32.tflite' (11.7 MB)\n\nExport complete (14.7s)\nResults saved to \u001b[1m/kaggle/working/runs/detect/train2/weights\u001b[0m\nPredict:         yolo predict task=detect model=/kaggle/working/runs/detect/train2/weights/best_saved_model/best_float32.tflite imgsz=640  \nValidate:        yolo val task=detect model=/kaggle/working/runs/detect/train2/weights/best_saved_model/best_float32.tflite imgsz=640 data=/kaggle/working/data.yaml  \nVisualize:       https://netron.app\nüí° Learn more at https://docs.ultralytics.com/modes/export\n","output_type":"stream"}],"execution_count":14}]}